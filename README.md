# Содержание

---

1. [`Описание`](#description)
2. [`Установка`](#installing)
3. [`Отладка`](#debugging)
4. [`Запуск тестов`](#tests)
5. [`Запуск нагрузочных тестов`](#load_tests)
   1. [`Тестирование платформы через прокси`](#load_tests_over_proxy)
   2. [`Тестирование платформы напрямую`](#load_tests_direct)
6. [`Генерация документации`](#make_docs)
   1. [`HTML`](#html-docs)
   2. [`PDF`](#pdf-docs)

---

**Полная текущая документация доступна по адресу https://mpc-peresvet.readthedocs.io.**
**В настоящее время документация обновляется каждый раз,**
**когда в ветку разработки `dev` добавляется**
**новая функциональность.**

# <a name="description"></a>Описание

**МПК-Пересвет** - платформа для автоматизации технических объектов.
Главная задача - построение модели технического объекта.
Модель объекта состоит из двух частей: статическая, в виде иерархии,
и динамическая - как совокупность всех вычислительных методов, привязанных
к узлам иерархии.

Платформа может использоваться для сбора, хранения, обработки данных, а также
автоматизации процессов, протекающих в рамках технического объекта.

Отличия от баз данных реального времени (Prometheus, VictoriaMetrics и т.д.):

1. Инфраструктура. Платформа представляет собой, в первую очередь,
   инфраструктурную надстройку над базой данных реального времени,
   т.е. предлагает создание иерархии объектов, каждый из которых обладает
   набором параметров (тэгов).
2. Расчётные тэги. У объекта могут быть параметры, которые рассчитываются
   на основании других параметров.
3. Внешние расчётные методы. К событиям, происходящим в платформе
   (изменения тэгов; тревоги; расписания) могут быть привязаны как
   расчётные методы тэгов, так и просто внешние методы,
   запускающие какие-либо внешние процессы.
4. Платформа позволяет не только собирать внешние данные, но и записывать
   (через коннекторы) данные во внешние источники.
   Таким образом, на базе платформы можно строить SCADA-системы,
   системы управления умным домом и т.д.

Говоря в общем, платформа МПК-Пересвет, в отличие от большинства баз данных
реального времени, нацелена не столько на сбор метрик,
сколько на автоматизацию технических объектов.

# <a name="installing"></a> Установка

## Установка для запуска

> :zap: Здесь описывается процесс установки платформы на одном компьютере.
> В первую очередь, для целей разработки.
> Для более полной информации по возможным вариантам установки
> см. документацию по продукту, раздел "Установка".

> :zap: Платформа тестировалась на Ubuntu 22.04.

1. Установите [Docker](https://docs.docker.com/get-docker/).
2. Скопируйте или склонируйте на свой компьютер этот проект.
   [Ссылка](https://github.com/mp-co-ru/mpc-peresvet).
3. Зайдите в корневую папку проекта и запустите на исполнение файл `run.sh`.
   В результате запустятся основные контейнеры:
   1. Платформа (peresvet);
   2. Иерархическая база (ldap);
   3. База данных реального времени (victoriametrics);
   4. Прокси-сервер Nginx (nginx);
   5. Grafana (grafana).

## Установка для разработки

В проекте используется модуль `python-ldap`, поэтому перед установкой
окружения проекта выполните команду:

```bash
$ sudo apt-get install build-essential python3-dev \
libldap2-dev libsasl2-dev slapd ldap-utils tox lcov valgrind \
libcairo2-dev pkg-config
```

После этого зайдите в корневую папку проекта и выполните:

```bash
$ pipenv shell
```

# <a name="debugging"></a> Отладка

**Пересвет** разрабатывается с использованием VSCode, поэтому отладка описана применительно к этому инструменту.

Для отладки в VSCode должен быть установлен плагин `ms-vscode-remote.remote-containers`.

Внутренняя настройка режима отладки происходит

Запуск отладки:

1. В папке `.vscode`, которая находится в корневой папке проекта создаем файл launch.json (если он еще не создан).
2. Помещаем данный код в этот файл
   ```{
    "version": "0.2.0",
    "configurations": [
        {
            "name": "Python: Remote Attach",
            "type": "python",
            "request": "attach",
            "connect": {
                "host": "localhost",
                "port": 5678
            },
            "pathMappings": [
                {
                    "localRoot": "${workspaceFolder}",
                    "remoteRoot": "."
                }
            ],
            "justMyCode": true
        }
    ]
   }
   ```
3. Создаем образ контейнера сервиса для отладки. `docker-compose -f <docker-compose file name> build --build-arg debug_svc=<service name>`, где `<service name>` – название сервиса, указанной в конфигурации nginx-unit (app | app_api | api_crud | model_crud)
4. Запускаем собранный образ сервиса командой `docker compose <docker-compose file name> up`, а также остальные сервисы, необходимые для работы платформы.
5. Создаем в VSCode новый терминал: `Terminal -> New terminal` (`Терминал -> Создать терминал`).
6. Ждем до тех пор, пока сервис для отладки не запустится окончательно.
7. Переходим в исходный файл сервиса, который был запущен в режиме отладки и ставим breakpoints для отладки.
8. Нажимаем `F5`...
9. Мы вошли в режим отладки сервиса.

## Настройка сервиса для запуска в режиме отладки

> Отладка сервисов работает на основе uvicorn, а не nginx-unit.
> В связи с этим для запуска сервиса в режиме отладки требуется создать отдельные конфигурационные файлы `Dockerfile` и `docker-compose.yml`

### Создание файла Dockerfile

Для создания файла Dockerfile для отладки сервиса необходимо добавить несколько директив к исходному файлу Dockerfile без режима отладки.

> Добавлять новые директивы необходимо в конец исходного Dockerfile файла, так как иначе при создании образа docker будет пересчитывать все закешированные слои заново.

1. `ARG debug_svc`. Задаем параметр `debug_svc` с помощью котороко можно будет выбирать, какой именно сервис мы хотим запустить в режиме отладки (например app_api).
2. `ENV DEBUG_SVC $debug_svc`. Задаем переменную окружения `DEBUG_SVC`, которая будет равнятся параметру `debug_svc`, заданому ранее.
3. `COPY docker/docker-files/common/debug_setup.py /usr/src`. Копируем файл `debug_setup.py`, который отвечает за настройку режима отладки внутри контейнера
4. `COPY --chmod=777 docker/docker-files/common/run_debug_setup.sh /docker-entrypoint.d/`. Копируем файл `run_debug_setup.sh` который запускает ранее скопированный файл `debug_setup.py` при инициализации контейнера. флагом `--chmod=777` даем ему полные права.

### Создание файла docker-compose.yml

Для создания файла docker-compose.yml для отладки сервиса необходимо добавить несколько директив к исходному файлу docker-compose.yml без режима отладки.

1. Добавить строку `- 5678:5678` в директиве `ports` (Открываем и пробрасываем порт 5678, порт для соединения с remote debugger).
2. Добавить директиву

   ```
   args:
     - DEBUG_SVC=${debug_svc}
   ```

   внутрь директивы `build`. Задаем значение переменной окружения DEBUG_SVC равное значению параметра debug_svc

# <a name="tests"></a>Запуск unit-тестов

Находясь в корневой папке проекта, запускаем файл `run_tests.sh`.

Будут запущены unit-тесты, также будет показана статистика покрытия тестами исходных кодов проекта.

В модуле `ldap3` есть проблема при работе в режиме mock-сервера: объект `Connection` в режиме работы
`MOCK_SYNC` возвращает результат в другом формате, нежели при нормальной работе.

Поэтому для прогона тестов создаётся дополнительный контейнер и каждый раз при новом запуске тестов
удаляются данные, записанные во время предыдущего теста.

После прогона тестов с помощью ldap-браузера (JXplorer) можно подсоединиться
к ldap-серверу, на котором прогонялись тесты. Он доступен по порту `3890`.

![ldap-test](pics/jxplorer.png 'ldap-test')

> :zap:Контейнер, на котором работает тестовый ldap-сервер, называется `ldap_test`.
> Не забудьте вручную остановить контейнер `ldap_test` командой
> `$ docker stop ldap_test`

# <a name="load_tests"></a>Запуск нагрузочных тестов

В настоящем разделе содержится инструкция для разворачивания полигона для
выполнения нагрузочных тестов для команд `data/set` и `data/get`.

Предполагается, что все команды выполняются в корневой папке проекта.

## 1. ldap image

Восстанавливаем из архива образ иерархической базы с 4000 тегов, для чего
выполняем команду

```bash
$ docker load -i load_tests/images/ldap_4000_tags.tar
```

## 2. Подготовка базы данных PostgreSQL

Выполним следующее: создадим две базы данных PostgreSQL для двух разных
типов тестов, для записи и для чтения данных. Обе базы будут идентичны
по структуре таблиц, только база для тестов на чтение будет заполнена данными.

### Создание пустой базы для тестов data/set

1. Создадим каталог для базы данных PostgreSQL. Этот каталог должен быть
   вне папки проекта, так как в противном случае построение контейнеров будет
   занимать очень много времени в связи с большим размером баз.

   Допустим, каталог базы будет располагаться в корневом каталоге:

   ```bash
   $ mkdir /psql_set_data
   ```

2. Создадим пустую базу.

   Для этого откроем файл `docker-compose.postgres.set_test.yml`
   и значение параметра `volumes` приведём к следующему виду:

   ```
   - /psql_set_data:/var/lib/postgresql/data
   ```

   Сохраним файл.

   Запустим контейнер с PostgreSQL:

   ```bash
   $ docker compose -f docker-compose.postgres.set_test.yml up
   ```

   В результате в созданном нами на предыдущем шаге каталоге будет создана
   база данных `peresvet` (параметры создания базы - в файле `.env`).

3. Создадим в базе данных таблицы (их имена будут соответствовать тегам
   в восстановленной нами из архива иерархической базе):
   ```bash
   $ pipenv shell
   $ cd load_tests
   $ python create_tables.py
   ```
   Запущенный скрипт откроет файл `tags_in_postgres.json`, в котором записаны
   id всех тегов и для каждого тега создаст таблицу.

Подготовка для тестов команды `data/set` завершена.

### Создание пустой базы для тестов data/get

Теперь необходимо создать аналогичную базу и заполнить её данными.

1. Продублируем созданную базу, для чего просто скопируем каталог уже
   созданной нами базы. Выполнять команду необходимо с правами администратора.

   ```bash
   $ sudo su
   # cp -apr /psql_set_data/ /psql_get_data
   # exit
   ```

2. Откроем файл `docker-compose.postgres.get_test.yml` и исправим параметр
   `volumes`:

   ```
   - /psql_get_data:/var/lib/postgresql/data
   ```

   Сохраним файл.

3. Запустим PostgreSQL с новой базой:

   ```bash
   $ docker compose -f docker-compose.postgres.get_test.yml up
   ```

4. Заполним данными базу:
   ```bash
   $ pipenv shell
   $ cd load_tests
   $ python set_data_to_db_many.py
   ```
   > :warning: Внимание! Процесс записи данных будет долгим.

## 3. Запуск тестов data/set

Запустим все необходимые контейнеры.

```bash
$ ./run_locust_data_set_prs-psql.sh
```

В скрипте указано, что будут запущены 4 копии сервиса `peresvet`.
Это число можно изменить, исходя из правила, что количество копий сервиса
равно числу ядер процессора.

В целях ускорения работы платформы уровень логирования во всех сервисах
понижен до минимального.

При запуске платформа начинает создавать кэш для каждого тега.
Для этого требуется некоторое время, в течение которого платформа не будет
отвечать на запросы.

При отсутствии логов определить, что построение кэша закончено, можно
по активности процессов: запускаем в консоли команду `top` и наблюдаем
за активностью процессов `slapd`, `uvicorn`. Как только активность
этих процессов упадёт, значит, кэши построены.

Запускаем браузер и вводим в адресную строку: `http://localhost:8089`.

![set-test](pics/locust.png 'set-test')

Указываем нужное количество пользователей, а также адрес - `http://nginx`.
В этом случае в тесте будут задействованы все запущенные экземпляры платформы.

Для теста одного экземпляра платформы, без nginx-прокси, в строке адреса
указываем `http://peresvet`.

После выполнения тестов можно очистить от данных базу. Для этого сначала
остановим все контейнеры, затем выполним команды:

```bash
$ docker compose -f docker-compose.postgres.set_test.yml up
$ cd load_tests
$ python delete_data.py
```

> :warning: Выполняйте скрипт удаления данных только на базе для теста
> data/set! Не путайте с data/get!

## 4. Запуск тестов data/get

Запуск тестов на получение данных аналогичен предыдущему, за исключением того,
что выполняется он скриптом

```bash
$ ./run_locust_data_get_prs-psql.sh
```

## 5. Создание новых тестов

В тестах data/set используется файл
`load_tests/src/locustfile_set_data_prs-psql.py`, а в тестах data/get -
`locustfile_get_data_prs-psql.py`.

Файлы можно расширять новыми тестами, а также создавать новые файлы.

## 6. Запуск теста реальной работы системы

Эмулируется одновременная работа 100 коннекторов, каждый из которых раз в
секунду записывает значения для 50 тегов, а также 50 экранов, каждый из
которых раз в секунду читает текущие значения для 28 тегов.

```bash
$ ./run_locust_real_job.sh
```

# <a name="make_docs"></a>Генерация документации

Документация создаётся с помощью инструмента
`"sphinx" <https://www.sphinx-doc.org/en/master/>`\_. Все необходимые пакеты
прописаны в `Pipfile` и устанавливаются автоматически при создании
окружения проекта.

## <a name="html-docs"></a> HTML

В консоли заходим в папку `docs` и выполняем команду

```bash
$ make html
```

Созданная документация будет расположена в папке `docs/build/html`.
Основной файл - `index.html`.

## <a name="pdf"></a> PDF

PDF вариант документации создаётся с помощью
`LaTeX <https://www.latex-project.org/>`\_.

Устанавливаем необходимые пакеты:

```bash
$ sudo apt-get install  texmaker gummi texlive texlive-full \
texlive-latex-recommended latexdraw intltool-debian lacheck \
lmodern luatex po-debconf tex-common texlive-binaries texlive-extra-utils \
texlive-latex-base texlive-latex-base-doc texlive-luatex texlive-xetex \
texlive-lang-cyrillic texlive-fonts-extra texlive-science \
texlive-latex-extra texlive-pstricks
```

Заходим в каталог `docs/latex` и выполняем команды:

```bash
$ pdflatex mpc_peresvet.tex
$ makeindex mpc_peresvet.idx
$ pdflatex mpc_peresvet.tex
```

В этой же папке появится сгенерированный файл документации
`mpc_peresvet.pdf`.

Для генерации исходных кодов в виде pdf-файла выполняем два раза одну и ту же
команду:

```bash
$ pdflatex sources.tex
$ pdflatex sources.tex
```
